{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing the Datasets**\n\nOn carefully examining the data given, the only useful column is the 'Description'. This column gives a brief insight (written by the author) regarding his/her life, personal interests and hobbies. In order to predict whether the person is anyway related to Healthcare. Hence, this column is translated from various languages(such as Portuguese, Spanish, Dutch, Italian, Arabic) to English. ***You can find the code that was used for the translation here: [](http://hello.com)***\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the training data\nauthor_data = pd.read_csv('../input/preprocessed_train.csv')\nauthor_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that now that we are using the pre-processed version of the previous data-set, (original) we have removed the attributes like: ***Name, Location, Twitter Handle*** as they are un-relevant in deciding whether the social-media account is that of a Health-Care professional."},{"metadata":{"trusted":true},"cell_type":"code","source":"# similarly importing the test-set for future predictions\nauthor_data_test = pd.read_csv('../input/preprocessed_test.csv')\nauthor_data_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking the Distribution of the Training Set**\n\nWe check the distribution, i.e., the number of data-points which are manually classified by the client as ***HEALTH-CARE PROFESSIONALS***. A simple balanced distibution will make it easier for the models to train."},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing the distribution\nsns.countplot(x='HCP_flag', data=author_data)\nax = plt.gca()\nax.set_xticklabels(('No', 'Yes'))\nplt.xlabel('Health-Care Professional')\nplt.ylabel('Count')\nplt.title('Distribution of Data (Training Set)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the number of data-pointsm having a health-care is far less compared to the ordinary profiles in the social media data-set. However, this is practically sound, and we need to proceed likewise."},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting the features and label to be used for prediction and testing \n# for the predictions we will be using this to get the future features\nauthor_data = author_data.loc[:, ['Description', 'HCP_flag']]\nauthor_data_test = author_data_test.loc[:, ['Description', 'HCP_flag']]\nauthor_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_data['Description'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the rows with Nan description\nauthor_data = author_data[pd.notna(author_data['Description'])]\nauthor_data.head()\n\n# TODO: why?","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Visualizing the Author Description**\n\nBy using the concept of WordCloud analysis, we will be taking a look at the set of words that were used to describe a health-care professional and the set, which does not describe a health-care professional. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\nis_hcp_data = author_data[author_data['HCP_flag'] == 1]\nis_not_hcp_data = author_data[author_data['HCP_flag'] == 0]\nwords_all = ' '.join(description for description in author_data['Description'])\nwords_is_hcp = \" \".join(description for description in is_hcp_data['Description'])\nwords_is_not_hcp = \" \".join(description for description in is_not_hcp_data['Description'])\n\n# creating the sub-plots\nfig, ax = plt.subplots(3, 1, figsize  = (30,30))\n\n# create and generate a word cloud image:\nwordcloud_all = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(words_all)\nwordcloud_is_hcp = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(words_is_hcp)\nwordcloud_is_not_hcp = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(words_is_not_hcp)\n\n# display the generated image:\nax[0].imshow(wordcloud_all, interpolation='bilinear')\nax[0].set_title('All Words', fontsize=30)\nax[0].axis('off')\nax[1].imshow(wordcloud_is_hcp, interpolation='bilinear')\nax[1].set_title('Words under Is HCP Class',fontsize=30)\nax[1].axis('off')\nax[2].imshow(wordcloud_is_not_hcp, interpolation='bilinear')\nax[2].set_title('Tweets under Is Not HCP Class',fontsize=30)\nax[2].axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some useful insights we get from this:-\n* We can see the importance of words like **'cancer'**, **'medicine'**, **'physician'**, **'oncology'**, **'surgeon'** are being higlighted as **highly frequent** in profiles of the social media handles, who are associated with health-care. This seems practical. \n***A doctor is sensible enough, to have a meaningful description.***\n* Few high frequency tokens such as **'health'**, **'tweet'**, **'cancer'** are frequently used in both the categorical classes. \n***Why would someone have **'cancer'** in their description?*** \n    We can conclude this in several ways:-\n        - Maybe he/she was a cancer survivor (like Yuvraj, Hugh Jackman)\n        - Maybe that is his/her zodiac sign (Psst! Nobody cares.)\n* Removing these words along with stops words would not impact the performance. "},{"metadata":{},"cell_type":"markdown","source":"**Pre-processing the data**\n\nEven though we are planning to use a better optimizer than the usual CountVectorizer class of the NLTK library, we need to futher remove the noise from the data, so that our prediction is more accurate. We may proceed as follows:-  \n**(A)** Removing punctuations\n**(B)** Converting to Lower-Case\n\n***As you can see, we have already transformed the data-set, during language translation. But, what else?***"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://yoast.com/app/uploads/2015/12/Stopwords_in_your_focus_keywords_FI.png\">>"},{"metadata":{},"cell_type":"markdown","source":"![](http://https://yoast.com/app/uploads/2015/12/Stopwords_in_your_focus_keywords_FI.png)"},{"metadata":{},"cell_type":"markdown","source":"**STOP WORDS!** \nThe definition of what’s a stop word may vary. You may consider a stop word a word that has high frequency on a corpus. Or you can consider every word that’s empty of true meaning given a context.\nWords such as articles and some verbs are usually considered stop words because they don’t help us to find the context or the true meaning of a sentence. These are words that can be removed without any negative consequences to the final model that you are training."},{"metadata":{"trusted":true},"cell_type":"code","source":"# trying to see what stop-words can be removed from our data-set\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nprint(stop_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we just get rid of them?\nWe will be coming back to this step, during the Vectorization phase of the text-data. For now, let's move forward!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at the final list of tokens without the stop-words\nimport nltk\nfrom nltk.tokenize import word_tokenize\nmerged_desc = pd.concat([author_data['Description'], author_data_test['Description']], axis=0)\n# fill the NaN values with 'X'\nmerged_desc.fillna('X', inplace=True)\nreviews = merged_desc.str.cat(sep=' ')\nimport re\nreviews = re.sub('[^a-zA-Z]', ' ', reviews)\ntokens = word_tokenize(reviews)\nvocabulary = set(tokens)\nprint('Total list of tokens: ', len(vocabulary))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# after removal of stop-words\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\ntokens = [w for w in tokens if (not w in stop_words and len(w) > 2)]\nprint(tokens)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, we have tried to refine the set of words which we are going to use ***by doing two things***:-\n* Removing the stop-words (can be also done, using **TfidfVectorizer**\n* Removing all the words having length of **less than 2** (these are totally not relevant, and will help us to further optimize our models)"},{"metadata":{},"cell_type":"markdown","source":"**Refining the 'Description' column further for training sets**\nWe include only those words in the 'Profile Description' that are present in the **tokens** set, recently constructed. Hence, we need not use the CountVectorizer method, and ***can further continue this rather adventurous journey!***"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n    A function that transforms the 'Description' column for each of the individual rows as described above.\n\"\"\"\n# remove the word 'tweet' from tokens\nauthor_data['Description'] = author_data['Description'].str.lower()\nauthor_data_test['Description'] = author_data_test['Description'].str.lower()\n\nauthor_data['Description'] = author_data['Description'].apply(lambda x: ' '.join([w for w in str(x).split() if (w in tokens and not w == 'tweet' and not w == 'tweets')]))\nauthor_data_test['Description'] = author_data_test['Description'].apply(lambda x: ' '.join([w for w in str(x).split() if (w in tokens and not w == 'tweet' and not w == 'tweets')]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_data_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Further visualizing our progress with the word-clouds. Let's see if there is any difference. ***Basically, reduction in noise.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\nis_hcp_data = author_data[author_data['HCP_flag'] == 1]\nis_not_hcp_data = author_data[author_data['HCP_flag'] == 0]\nwords_all = ' '.join(description for description in author_data['Description'])\nwords_is_hcp = \" \".join(description for description in is_hcp_data['Description'])\nwords_is_not_hcp = \" \".join(description for description in is_not_hcp_data['Description'])\n\n# creating the sub-plots\nfig, ax = plt.subplots(3, 1, figsize  = (30,30))\n\n# create and generate a word cloud image:\nwordcloud_all = WordCloud(max_font_size=50, max_words=100, background_color='black').generate(words_all)\nwordcloud_is_hcp = WordCloud(max_font_size=50, max_words=100, background_color='black').generate(words_is_hcp)\nwordcloud_is_not_hcp = WordCloud(max_font_size=50, max_words=100, background_color='black').generate(words_is_not_hcp)\n\n# display the generated image:\nax[0].imshow(wordcloud_all, interpolation='bilinear')\nax[0].set_title('All Words', fontsize=30)\nax[0].axis('off')\nax[1].imshow(wordcloud_is_hcp, interpolation='bilinear')\nax[1].set_title('Words under Is HCP Class',fontsize=30)\nax[1].axis('off')\nax[2].imshow(wordcloud_is_not_hcp, interpolation='bilinear')\nax[2].set_title('Tweets under Is Not HCP Class',fontsize=30)\nax[2].axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Well! Is that it?***"},{"metadata":{},"cell_type":"markdown","source":"**Stemming**\n\nIn natural language processing, there may come a time when we want the model to recognize that the words “ask” and “asked” are just different tenses of the same verb. This is the idea of reducing different forms of a word to a core root. Words that are derived from one another can be mapped to a central word or symbol, especially if they have the same core meaning.\nMaybe this is in an information retrieval setting and in-order want to boost the algorithm’s recall. Or perhaps you are trying to analyze word usage in a corpus and wish to condense related words so that you don’t have as much variability. Either way, this technique of text normalization may be useful to you.\n\n"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/660/0*o8l4UfdWOL2KTljk.jpg\">>"},{"metadata":{},"cell_type":"markdown","source":"With stemming, words are reduced to their word stems. A word stem need not be the same root as a dictionary-based morphological root, it just is an equal to or smaller form of the word.\n\n***We won't be using this approach, although we have the description data in English, as we need to preserve the authenticty of the technical (medical) terms!***"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Making the Vectorizer**\n\nWe will further create the TfidfVectorizer to generate the sparse-matrix of features that will be taken as input, to the model. There are several reasons for using this, as the Vectorizer:-\n\n**1. Tf** stands for Term Frequency. Let's try to understand, what that means! **It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.**\n\n**2. idf** stands for Inverse Document Frequency. **It is used to calculate the weight of rare words across all documents in the corpus.**\n\nHence, unlike CountVectorizer class this model will try to give some importance to the rare-scientific terms like **Neuro-surgeon**, **Pharmacy**, etc. There is a weightage that is involved. It is a measure used to evaluate how important a word is, to a document, in a collection of documents."},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the features\nX = author_data['Description']\ny = author_data['HCP_flag']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the vectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\ntrain_vectors = vectorizer.fit_transform(X_train)\ntest_vectors = vectorizer.transform(X_test)\nprint(train_vectors.shape, test_vectors.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hence, we see that our sparse-matrix contains 11922 different words (as features) which will be used to make the prediction models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the set of words that were used in the feature column\nprint(vectorizer.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating and Evaluating Models**\n\nNow that we have created the set of vectors, we try and predict the results, with different models. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ndef plot_roc_curve(y_test, y_prob, model_name):\n    from sklearn.metrics import roc_curve, auc\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8, 8))\n    plt.title('Receiver Operating Characteristic {} Model'.format(model_name))\n    plt.plot(false_positive_rate, true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],linestyle='--')\n    plt.axis('tight')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(y_test, y_pred, y_score, model_name):\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    print ('Confusion Matrix for {} Model'.format(model_name))\n    print (cm)\n    print ('Classification Report for {} Model'.format(model_name))\n    print (metrics.classification_report(y_test, y_pred, digits=6))\n    print ('Area under under ROC curve for {} Model'.format(model_name))\n    print (metrics.roc_auc_score(y_test, y_score))\n    plot_roc_curve(y_test, y_score, model_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A MultinomialNB Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB().fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.metrics  import roc_auc_score\npredicted = model.predict(test_vectors)\nprint(roc_auc_score(y_test, predicted))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_prob = model.predict_proba(test_vectors)\nevaluate_model(y_test, predicted, predicted_prob[:, [1]], 'Multinomial Naive-Bayes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# building a random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nmodel = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 100)\n\nmodel.fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluating the random forest classifier\nfrom  sklearn.metrics  import roc_auc_score\npredicted = model.predict(test_vectors)\nprint(roc_auc_score(y_test,predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation of Random Forests Classifier\npredicted_prob = model.predict_proba(test_vectors)\nevaluate_model(y_test, predicted, predicted_prob[:, [1]], 'Random Forests Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# making an XGBoost classifier with hyperparameter tuning\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV  #Additional scklearn functions\n\n# tuning the number of decision trees\nmodel = XGBClassifier(learning_rate=0.01,\n                    min_child_weight=3, gamma=0.3, subsample=0.6, colsample_bytree=1.0,\n                    objective='binary:logistic', eval_metric='auc', nthread=4, scale_pos_weight=1, seed=27, n_jobs=4)\nn_estimators = [300] #[100, 150, 200, 250,\nmax_depth = [2, 4, 6, 8]\n\nparams = dict(n_estimators=n_estimators, max_depth=max_depth)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\ngrid = GridSearchCV(model, params, scoring='roc_auc', n_jobs=10, cv=3)\ngrid_result = grid.fit(train_vectors, y_train)\nprint('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the final model\nfrom xgboost.sklearn import XGBClassifier\ntuned_xg = XGBClassifier(max_depth=8, n_estimators=300,\n                    min_child_weight=3, gamma=0.3, subsample=0.6, colsample_bytree=1.0,\n                    objective='binary:logistic', eval_metric='auc', nthread=4, scale_pos_weight=1, seed=27, n_jobs=4)\ntuned_xg.fit(train_vectors, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation of Random Forests Classifier\npredicted_prob = tuned_xg.predict_proba(test_vectors)\nevaluate_model(y_test, predicted, predicted_prob[:, [1]], 'XGBoost Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation of the Final Model**"},{"metadata":{},"cell_type":"markdown","source":"Looking at the confusion matrix, we can say, that the data is carefully normalized. This is because of the default working of the Ensemble learning algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the final results for testing part\nX_valid = author_data_test['Description']\nX_valid = X_valid.fillna('X')\nvalid_vectors = vectorizer.transform(X_valid)\n\nauthor_data_test['HCP_flag'] = tuned_xg.predict_proba(valid_vectors)[:, 1]\n\nauthor_data_test.to_csv('submisstion.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}